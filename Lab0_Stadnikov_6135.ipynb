{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fm0RRqE_WQzw",
        "outputId": "e73529ac-445f-45d1-c852-04728071a9be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install pycuda"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pycuda\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/61/47d3235a4c13eec5a5f03594ddb268f4858734e02980afbcd806e6242fa5/pycuda-2020.1.tar.gz (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 10.5MB/s \n",
            "\u001b[?25hCollecting pytools>=2011.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b7/30/c9362a282ef89106768cba9d884f4b2e4f5dc6881d0c19b478d2a710b82b/pytools-2020.4.3.tar.gz (62kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 9.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from pycuda) (4.4.2)\n",
            "Collecting appdirs>=1.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/00/2344469e2084fb287c2e0b57b72910309874c3245463acd6cf5e3db69324/appdirs-1.4.4-py2.py3-none-any.whl\n",
            "Collecting mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/37/0e706200d22172eb8fa17d68a7ae22dec7631a0a92266634fb518a88a5b2/Mako-1.1.3-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 8.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (1.18.5)\n",
            "Requirement already satisfied: dataclasses>=0.7 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (0.7)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from mako->pycuda) (1.1.1)\n",
            "Building wheels for collected packages: pycuda, pytools\n",
            "  Building wheel for pycuda (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2020.1-cp36-cp36m-linux_x86_64.whl size=620887 sha256=2f6098395305b87e2127ade39fe5c1245c5f278f1170f785818abb489a7e7ff8\n",
            "  Stored in directory: /root/.cache/pip/wheels/8f/78/d1/5bb826f81d9d490297a348d818ff3ee6dd6f2075b06dde6ea0\n",
            "  Building wheel for pytools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytools: filename=pytools-2020.4.3-py2.py3-none-any.whl size=61374 sha256=b0f9699c6e75f486ea1d73db7f3895c69d79e47afa145259c809acc7e2c7c8a1\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/c7/81/a22edb90b0b09a880468b2253bb1df8e9f503337ee15432c64\n",
            "Successfully built pycuda pytools\n",
            "Installing collected packages: appdirs, pytools, mako, pycuda\n",
            "Successfully installed appdirs-1.4.4 mako-1.1.3 pycuda-2020.1 pytools-2020.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziZX7VezGOEK",
        "outputId": "234bab16-4d2a-4fa0-923a-b82e32ce39eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "import pycuda.autoinit\n",
        "\n",
        "from pycuda.tools import make_default_context\n",
        "make_default_context().get_device().name()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla T4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YZUH6zOdJJl"
      },
      "source": [
        "import numpy as np\n",
        "from numpy import linalg as la\n",
        "from pycuda import driver, compiler, gpuarray, tools\n",
        "import pycuda.autoinit\n",
        "import time\n",
        "\n",
        "m_size = 100\n",
        "\n",
        "def matmul_GPU(a_gpu,b_gpu,m_size=m_size):\n",
        "    kernel_code_template = \"\"\"\n",
        "    __global__ void MatrixMulKernel(float *A, float *B, float *C)\n",
        "    {\n",
        "\n",
        "      const uint wA = %(m_size)s;\n",
        "      const uint wB = %(m_size)s;\n",
        "\n",
        "      const uint bx = blockIdx.x;\n",
        "      const uint by = blockIdx.y;\n",
        "\n",
        "      const uint tx = threadIdx.x;\n",
        "      const uint ty = threadIdx.y;\n",
        "\n",
        "      const uint aBegin = wA * %(b_size)s * by;\n",
        "      const uint aEnd = aBegin + wA - 1;\n",
        "\n",
        "      const uint aStep = %(b_size)s;\n",
        "\n",
        "      const uint bBegin = %(b_size)s * bx;\n",
        "      const uint bStep = %(b_size)s * wB;\n",
        "\n",
        "      float Csub = 0;\n",
        "\n",
        "      for (int a = aBegin, b = bBegin;\n",
        "           a <= aEnd;\n",
        "           a += aStep, b += bStep)\n",
        "        {\n",
        "\n",
        "          __shared__ float As[%(b_size)s][%(b_size)s];\n",
        "\n",
        "          __shared__ float Bs[%(b_size)s][%(b_size)s];\n",
        "\n",
        "          As[ty][tx] = A[a + wA * ty + tx];\n",
        "          Bs[ty][tx] = B[b + wB * ty + tx];\n",
        "\n",
        "          __syncthreads();\n",
        "          for (int k = 0; k < %(b_size)s; ++k)\n",
        "            Csub += As[ty][k] * Bs[k][tx];\n",
        "          __syncthreads();\n",
        "        }\n",
        "\n",
        "      const uint c = wB * %(b_size)s * by + %(b_size)s * bx;\n",
        "      C[c + wB * ty + tx] = Csub;\n",
        "    }\n",
        "    \"\"\"\n",
        "\n",
        "    t_size = 2\n",
        "    b_size = t_size\n",
        "\n",
        "    kernel_code = kernel_code_template % {\n",
        "        'm_size': m_size,\n",
        "        'b_size': b_size,\n",
        "        }\n",
        "\n",
        "    mod = compiler.SourceModule(kernel_code)\n",
        "    \n",
        "    c_gpu = gpuarray.empty((m_size, m_size), np.float32)\n",
        "\n",
        "    matrixmul = mod.get_function(\"MatrixMulKernel\")\n",
        "\n",
        "    matrixmul(\n",
        "        a_gpu, b_gpu,\n",
        "        c_gpu,\n",
        "        grid = (m_size // t_size, m_size // t_size),\n",
        "        block = (t_size, t_size, 1),\n",
        "        )\n",
        "\n",
        "    return c_gpu\n",
        "\n",
        "\n",
        "def matmul_CPU(matrix1, matrix2):\n",
        "    rmatrix = np.zeros(shape=(matrix1.shape[0], matrix2.shape[1]))\n",
        "    for i in range(len(matrix1)):\n",
        "        for j in range(len(matrix2[0])):\n",
        "            for k in range(len(matrix2)):\n",
        "                rmatrix[i][j] += matrix1[i][k] * matrix2[k][j]\n",
        "    return rmatrix"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WucFeklndMUq",
        "outputId": "5a9ec702-1965-4273-c4e9-725ed27aa504",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cpu_time = []\n",
        "gpu_time = []\n",
        "diffs = []\n",
        "\n",
        "for size in [128, 256, 512]:\n",
        "    a_cpu = np.random.randn(size, size).astype(np.float32)\n",
        "    b_cpu = np.random.randn(size, size).astype(np.float32)\n",
        "\n",
        "    print(\"Размерность матрицы:\", size)\n",
        "    \n",
        "    startCPU = time.time()\n",
        "    c_cpu = matmul_CPU(a_cpu, b_cpu)\n",
        "    endCPU = time.time()\n",
        "    timeCPU = endCPU -startCPU\n",
        "\n",
        "    print(\"время на CPU:\", timeCPU)\n",
        "    cpu_time.append(timeCPU)\n",
        "\n",
        "    a_gpu = gpuarray.to_gpu(a_cpu)\n",
        "    b_gpu = gpuarray.to_gpu(b_cpu)\n",
        "\n",
        "    startGPU = time.time()\n",
        "    c_gpu = matmul_GPU(a_gpu, b_gpu, size)\n",
        "    endGPU = time.time()\n",
        "    timeGPU = endGPU-startGPU\n",
        "\n",
        "    print(\"время на GPU:\", timeGPU)\n",
        "    gpu_time.append(timeGPU)\n",
        "\n",
        "    differensetime = timeCPU-timeGPU\n",
        "    print(\"CPU-GPU:\", differensetime)\n",
        "    diffs.append(differensetime)\n",
        "    \n",
        "    print (\"___________________________\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Размерность матрицы: 128\n",
            "время на CPU: 2.354503631591797\n",
            "время на GPU: 0.9202377796173096\n",
            "CPU-GPU: 1.4342658519744873\n",
            "___________________________\n",
            "Размерность матрицы: 256\n",
            "время на CPU: 19.08896255493164\n",
            "время на GPU: 0.27205991744995117\n",
            "CPU-GPU: 18.81690263748169\n",
            "___________________________\n",
            "Размерность матрицы: 512\n",
            "время на CPU: 153.40163278579712\n",
            "время на GPU: 0.29764509201049805\n",
            "CPU-GPU: 153.10398769378662\n",
            "___________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}